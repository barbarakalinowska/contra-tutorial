{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python_in_Life_Sciences_upd.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6FDEhN_aZX3",
        "colab_type": "text"
      },
      "source": [
        "# Python in Life Sciences\n",
        "\n",
        "\n",
        "The aim o the tutorial is to show usage of the main Python tools used in bioinformatics contexts and to present a workflow of preparing a simple CLI application.\n",
        "\n",
        "\n",
        "Outline:\n",
        "1. Prototyping\n",
        "    * processing SAM files (pysam)\n",
        "    * processing TSV files (pandas, pyarrow)\n",
        "    * adding multiprocessing \n",
        "2. CLI application counting gRNAs from alignment files\n",
        "    \n",
        "Problem:\n",
        "Let's assume we have a data from the CRISPR screen experimemt. For the purpose of the tutorial we are going to focus on one step of the data processing - counting genes indentified by guide RNA sequences aligned to the library. The real analysis requires to start with demultiplexing, trimming the reads and performing and alignment to a library. Let's assume we have these steps performed already."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll_U68GHaZX5",
        "colab_type": "text"
      },
      "source": [
        "Task: process the SAM file in order to get counts of genes indentified by the gRNAs. Write results to a TSV file and visualize them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8cByD866yyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -Lk -o data.zip 'https://github.com/barbarakalinowska/tutorial-python/blob/master/data.zip?raw=true'\n",
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai5Z85-IazYc",
        "colab_type": "text"
      },
      "source": [
        "## Install required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h5j_lRkayQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install pysam biopython pandas pyarrow matplotlib seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBkD_18lbJCT",
        "colab_type": "text"
      },
      "source": [
        "Upload the data and locate them in /content/data/ folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_LQUQaFaZX6",
        "colab_type": "text"
      },
      "source": [
        "## Processing SAM files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqRTi3OmaZX7",
        "colab_type": "text"
      },
      "source": [
        "#### Approach 1: parse SAM file with pysam module read by read.\n",
        "\n",
        "Firstly, let's import some basic packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c93dk-BuaZX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing as mp\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import pysam\n",
        "import seaborn as sns\n",
        "\n",
        "from Bio import SeqIO\n",
        "from collections import defaultdict\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BsoYiFmaZX_",
        "colab_type": "text"
      },
      "source": [
        "Assuming someone would like to parse the library in order to obtain all gRNAs identifiers, the easiest way is to parse FASTA with with the library with the Biopython module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53vSOafGchZx",
        "colab_type": "text"
      },
      "source": [
        "Convert the content of the `screen_library.fasta` to dictionary and count gRNA sequences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H3l5AzMdkYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "library = \"data/screen_library.fasta\"\n",
        "\n",
        "gRNA_dict = SeqIO.to_dict(SeqIO.parse(library, \"fasta\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf_Ycb49ef01",
        "colab_type": "text"
      },
      "source": [
        "Count gRNA identifiers for each unique gene:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8UCLwy0aZYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genes_count = defaultdict(int)\n",
        "with open(library, \"r\") as handle:\n",
        "    for record in SeqIO.parse(handle, \"fasta\"):\n",
        "        genes_count[record.id.split(\"_\")[0]] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEgQ_9uVaZYD",
        "colab_type": "text"
      },
      "source": [
        "Parse the SAM file and print some information about each read:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnGbsVt0aZYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sam = pysam.AlignmentFile(\"data/sam_files/sample1.sam\", \"r\")\n",
        "for read in sam.fetch():\n",
        "    print(read.reference_name, read.reference_name, read.is_unmapped)\n",
        "    print(read.query_name, read.query_sequence, read.query_length, read.get_tags())\n",
        "sam.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqENhyMDaZYH",
        "colab_type": "text"
      },
      "source": [
        "Count reads mapped to gRNA sequences per gene."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGqM-g4daZYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genes_count = defaultdict(int)\n",
        "sam_file = \"data/sam_files/sample1.sam\"\n",
        "sam = pysam.AlignmentFile(sam_file, \"r\")\n",
        "for read in sam.fetch():\n",
        "    if not read.is_unmapped:\n",
        "        genes_count[read.reference_name.split(\"_\", 1)[0]] += 1\n",
        "sam.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewrf0sy_mMto",
        "colab_type": "text"
      },
      "source": [
        "Add filters for reads - maximum read length - 20 and the maximum number of mismatches - 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9msl5goBmdS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genes_count = defaultdict(int)\n",
        "sam_file = \"data/sam_files/sample1.sam\"\n",
        "sam = pysam.AlignmentFile(sam_file, \"r\")\n",
        "for read in sam.fetch():\n",
        "    if not read.is_unmapped and read.qlen <= 20 and read.get_tag('NM') <= 1:\n",
        "        genes_count[read.reference_name.split(\"_\", 1)[0]] += 1\n",
        "sam.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuUGXDaxaZYM",
        "colab_type": "text"
      },
      "source": [
        "Now, we save the results in a TSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHD_CZciaZYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts_report = 'report_test.tsv'\n",
        "header = [\"gene\", \"count\"]\n",
        "with open(counts_report, 'w') as csvfile:\n",
        "    gene_count_csv = csv.writer(csvfile, delimiter='\\t')\n",
        "    gene_count_csv.writerow(header)\n",
        "    for gene in sorted(genes_count.keys()):\n",
        "        gene_count_csv.writerow([gene, genes_count[gene]])   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io345rF-aZYQ",
        "colab_type": "text"
      },
      "source": [
        "Let's gather all the steps into functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C8dMlUZaZYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_report(genes_count, report):\n",
        "    header = [\"gene\", \"count\"]\n",
        "    with open(report, 'w') as csvfile:\n",
        "        gene_count_csv = csv.writer(csvfile, delimiter='\\t')\n",
        "        gene_count_csv.writerow(header)\n",
        "        for gene in sorted(genes_count.keys()):\n",
        "            gene_count_csv.writerow([gene, genes_count[gene]])  \n",
        "\n",
        "            \n",
        "def count_genes_pysam(sam_aln, report):\n",
        "    sam = pysam.AlignmentFile(sam_aln, \"rb\")\n",
        "    genes_count = defaultdict(int)\n",
        "    for read in sam.fetch():\n",
        "        if not read.is_unmapped and read.qlen <= 20 and read.get_tag('NM') <= 1:\n",
        "            genes_count[read.reference_name.split(\"_\", 1)[0]] += 1\n",
        "    sam.close()\n",
        "    write_report(genes_count, report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPjsXu19aZYU",
        "colab_type": "text"
      },
      "source": [
        "And check the function's performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-w2cbwEaZYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%timeit count_genes_pysam(\"data/sam_files/sample1.sam\", \"counts_report1.tsv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceNQh7H3aZYY",
        "colab_type": "text"
      },
      "source": [
        "## Processing TSV files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NAOx34SaZYZ",
        "colab_type": "text"
      },
      "source": [
        "#### Approach 2: treat the SAM file as a TSV file.\n",
        "\n",
        "We are going to use pandas to process the TSV file quickly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD7WQPLPaZYZ",
        "colab_type": "text"
      },
      "source": [
        "Because the SAM file do not have a constant number of columns, we need to define the columns before we read in the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNiH9796aZYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = [\"read_id\", \"flags_sum\", \"ref\", \"pos\", \"quality\", \"cigar\", \n",
        "        \"ref_aln\", \"aln_pos\", \"insert\", \"read_seq\", \"aln\", \n",
        "        \"opt1\", \"opt2\", \"opt3\", \"opt4\", \"opt5\", \"opt6\", \"opt7\" ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVmiLBB1aZYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aln = pd.read_csv(\"data/sam_files/sample1.sam\", delimiter=\"\\t\", names=column_names, comment=\"@\", \n",
        "                  index_col=False, compression='infer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGyXtKeraZYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aln.to_csv(\"data/tsv_files/sample1.tsv.gz\", sep=\"\\t\", index=False, compression=\"gzip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nOZi-NHaZYh",
        "colab_type": "text"
      },
      "source": [
        "Let's quickly investigate the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmtFye4ZaZYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aln.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0vUVoR_aZYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aln.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMaBxJScaZYn",
        "colab_type": "text"
      },
      "source": [
        "We would like to keep only aligned reads, so we can filter out the unmapped reads:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK6s91VkaZYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aln['cigar'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVDreMtkaZYq",
        "colab_type": "text"
      },
      "source": [
        "The unmapped reads should be removed, so filter out the rows with '\\*' in the 'cigar' field and print the new number of rows: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR_FraEYaZYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aln_filtered = aln[aln['cigar'] != \"*\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmywBFkxpvsK",
        "colab_type": "text"
      },
      "source": [
        "Add columne \"gene\" containing genes identifiers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bun_KYgWaZYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aln_filtered['gene'] = aln_filtered['ref'].str.split(\"_\", 1, expand=True)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbBDEWXG7Mq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aln_filtered.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQFY2EGPqH0B",
        "colab_type": "text"
      },
      "source": [
        "Add filtering by the maximum number of mimatches - 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dbjW_9YqHGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Firstly, the rows with NaN values in the 'opt3' columns are removed\n",
        "aln_filtered = aln_filtered[~aln_filtered.opt3.isna()]\n",
        "# The column 'MN' is added with a value provided by the 'MN' tag\n",
        "aln_filtered['MN'] = aln_filtered['opt3'].str.split(\":\", expand=True)[2].astype(int)\n",
        "# The rows with more than 1 mismatch are removed\n",
        "aln_filtered = aln_filtered[aln_filtered.MN <= 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMKHYFkiaZY2",
        "colab_type": "text"
      },
      "source": [
        "Now, let's use aggregation function to count occurence of genes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpiQ-n-vaZY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genes_count = aln_filtered.groupby('gene').size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnzwY6B5aZY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genes_count.to_csv(\"counts_report2.tsv\", sep=\"\\t\", header=[\"count\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwRuwQgwaZY8",
        "colab_type": "text"
      },
      "source": [
        "All the processing will be now gathered as a single function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwoECLY6aZY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_genes_pandas(sam_aln, report, cols):\n",
        "    aln = pd.read_csv(sam_aln, delimiter=\"\\t\", names=cols, comment=\"@\", \n",
        "                  index_col=False, compression='infer')\n",
        "    aln = aln[aln['cigar'] != \"*\"]\n",
        "    aln['gene'] = aln['ref'].str.split(\"_\", 1, expand=True)[0]\n",
        "    genes_count = aln.groupby('gene').size()\n",
        "    genes_count.to_csv(report, sep=\"\\t\", header=[\"count\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkNi146JaZY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%time count_genes_pandas(\"data/sam_files/sample1.sam\", \"count_report_pd.tsv\", column_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D18_1ajtaZZE",
        "colab_type": "text"
      },
      "source": [
        "## Parquet files\n",
        "\n",
        "#### Approach 3: converting the file into parquet files.\n",
        "In this approach we are testing what may be a benefit of storing the data in a parquet files instead of TSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGmfCmz0aZZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd_file = pd.read_table('data/sam_files/sample1.sam', comment=\"@\", \n",
        "                       names=column_names, index_col=False, compression='infer')\n",
        "pq.write_table(pa.Table.from_pandas(pd_file), 'data/sample1.pq', compression='snappy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Cqp8FhaZZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_genes_pq(pq_file, report):\n",
        "    aln = pd.read_parquet(pq_file, use_threads=True)\n",
        "    aln = aln[aln['cigar'] != \"*\"]\n",
        "    aln['gene'] = aln['ref'].str.split(\"_\", 1, expand=True)[0]\n",
        "    genes_count = aln.groupby('gene').size().to_frame(name=\"count\")\n",
        "    genes_count.to_csv(report, sep=\"\\t\", header=[\"count\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL0qTw8kaZZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%time count_genes_pq(\"data/sample1.pq\", \"data/count_report.tsv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TUOXxj2aZZM",
        "colab_type": "text"
      },
      "source": [
        "## Multiprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36iUYLGSaZZN",
        "colab_type": "text"
      },
      "source": [
        "#### Approach 4: dividing a file into chunks\n",
        "\n",
        "This approach may be especially useful if large files will be processed and when someone would like to avoid reading the whole file into memory.  Also, if someone would like to process the large file and keep intermediate results.\n",
        "In this approach we are going to use pyarrow module, which allows us to write data into parquet files. One of very important advantage of this operation is improving the peformance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ravyEJplwVi2",
        "colab_type": "text"
      },
      "source": [
        "Firstly, devide the sam file into chunks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB_SK91WaZZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reader = pd.read_table('data/sam_files/sample1.sam', chunksize=1e3, comment=\"@\", \n",
        "                       names=column_names, index_col=False, compression='infer')\n",
        "\n",
        "for chunk_no, chunk in enumerate(reader):\n",
        "    pq.write_table(pa.Table.from_pandas(chunk),\n",
        "    os.path.join('data/pq_files_in', 'aln-{:04d}.parquet'.format(chunk_no)), compression='snappy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Vd6LJfwkL9",
        "colab_type": "text"
      },
      "source": [
        "Prepare a function which returns a list of genes from gRNA IDs to which reads were mapped:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrXeGHRfaZZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_genes(df):\n",
        "    df = df[df['cigar'] != \"*\"]\n",
        "    df['gene'] = df['ref'].str.split(\"_\", 1, expand=True)[0]\n",
        "    return df[['gene']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnZY9-C3wBIy",
        "colab_type": "text"
      },
      "source": [
        "Prepare function which extract genes from parquet file and saves it as an intermediate output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAw_5dmIaZZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_aln(filename, out_dir):\n",
        "    chunk = pq.read_table(filename, use_threads=True).to_pandas()\n",
        "    chunk_genes = extract_genes(chunk)\n",
        "    pq.write_table(pa.Table.from_pandas(chunk_genes), \n",
        "                   os.path.join(out_dir, os.path.basename(filename)), \n",
        "                   compression='snappy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MavwQymhxjSw",
        "colab_type": "text"
      },
      "source": [
        "Extract genes from all parquet files using multiprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq0xTHN7aZZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%timeit\n",
        "pool = mp.Pool()\n",
        "out_dir = \"data/pq_files_out\"\n",
        "in_dir = \"data/pq_files_in\"\n",
        "for filename in glob.glob(os.path.join(in_dir, '*.parquet')):\n",
        "    pool.apply_async(process_aln, args=(filename, out_dir, ))\n",
        "pool.close()\n",
        "pool.join()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcl2Z776x5_t",
        "colab_type": "text"
      },
      "source": [
        "Add merging the outputs to obtain the final report:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hAmfmR4aZZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "df = pq.read_table('data/pq_files_out/', use_threads=True).to_pandas()\n",
        "genes = df.groupby('gene').size().to_frame(name=\"count\")\n",
        "genes.to_csv('counts_report_pq.tsv', sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaNeFQzcyOoM",
        "colab_type": "text"
      },
      "source": [
        "Finally, measure the time of processing the file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krBy_lHJaZZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "pool = mp.Pool()\n",
        "out_dir = \"data/pq_files_out\"\n",
        "in_dir = \"data/pq_files_in\"\n",
        "for filename in glob.glob(os.path.join(in_dir, '*.parquet')):\n",
        "    pool.apply_async(process_aln, args=(filename, out_dir, ))\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "df = pq.read_table('data/pq_files_out/', use_threads=True).to_pandas()\n",
        "genes = df.groupby('gene').size().to_frame(name=\"count\")\n",
        "genes.to_csv('counts_report_pq.tsv', sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FFNsVcCaZZa",
        "colab_type": "text"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLmxGXa0aZZb",
        "colab_type": "text"
      },
      "source": [
        "Now, we are going to process all four samples and then the results will be plotted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTyacOdAaZZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sam_dir = \"./data/sam_files/\"\n",
        "sam_files = glob.glob(os.path.join(sam_dir, '*.sam'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7VPGT_TVaZZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sam_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUeoq9TAaZZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_genes_pandas(sam_aln, report, cols):\n",
        "    aln = pd.read_csv(sam_aln, delimiter=\"\\t\", names=cols, comment=\"@\", \n",
        "                  index_col=False, compression='infer')\n",
        "    aln = aln[aln['cigar'] != \"*\"]\n",
        "    aln['gene'] = aln['ref'].str.split(\"_\", 1, expand=True)[0]\n",
        "    genes_count = aln.groupby('gene').size()\n",
        "    genes_count.to_csv(report, sep=\"\\t\", header=[\"count\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znlCeoJ6aZZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sam_file in sam_files:\n",
        "    sample = os.path.basename(sam_file).split(\".\")[0]\n",
        "    print(sample)\n",
        "    count_genes_pandas(sam_file, os.path.join(\"data/tsv_files/\", sample+\"_report.tsv\"), column_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikajrPBZaZZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_counts_1 = pd.read_csv(\"data/tsv_files/sample1_report.tsv\", sep=\"\\t\")\n",
        "gene_counts_1 = gene_counts_1.set_index('gene')\n",
        "gene_counts_2 = pd.read_csv(\"data/tsv_files/sample2_report.tsv\", sep=\"\\t\")\n",
        "gene_counts_2 = gene_counts_2.set_index(\"gene\")\n",
        "gene_counts_3 = pd.read_csv(\"data/tsv_files/sample3_report.tsv\", sep=\"\\t\")\n",
        "gene_counts_3 = gene_counts_3.set_index(\"gene\")\n",
        "gene_counts_4 = pd.read_csv(\"data/tsv_files/sample4_report.tsv\", sep=\"\\t\")\n",
        "gene_counts_4 = gene_counts_4.set_index(\"gene\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz4H3-PyaZZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_counts_all =  pd.merge(gene_counts_1, gene_counts_2,\n",
        "                            on=\"gene\", how=\"outer\", suffixes=['_1', '_2'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qc_brGpaZZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_counts_all_p2 =  pd.merge(gene_counts_3, gene_counts_4,\n",
        "                            on=\"gene\", how=\"outer\", suffixes=['_3', '_4'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GiX-y3kaZZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_counts_all = pd.merge(gene_counts_all, gene_counts_all_p2, on=\"gene\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RkyUkH-aZZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_counts_all.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1uGp3QBaZZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_counts_all.columns = [\"sample1\", \"sample2\", \"sample3\", \"sample4\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYWXPEJRaZZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "data = pd.melt(gene_counts_all)\n",
        "ax = sns.boxplot(x=\"variable\", y=\"value\", data=data)\n",
        "ax.set(xlabel='sample', ylabel='counts', title=\"Genes abundance\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEFC_QAjaZZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sample in gene_counts_all.columns:\n",
        "    ax = sns.distplot(gene_counts_all[sample].dropna(), kde=False, hist=True, label=sample)\n",
        "ax.set(xlabel='counts', title=\"Genes abundance\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw50Z5kxmQaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sample in gene_counts_all.columns:\n",
        "     ax = sns.distplot(gene_counts_all[sample].dropna(), kde=True, kde_kws = {'shade': True, 'linewidth': 3}, hist=True, label=sample)\n",
        "ax.set(xlabel='counts', title=\"Genes abundance\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
